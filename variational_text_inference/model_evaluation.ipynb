{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_loader_utils import TextLoader\n",
    "import pickle as cPickle\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "from variational_model import NVDM\n",
    "from vector_utils import find_norm\n",
    "from tf_common_utils import load_model , save_model\n",
    "\n",
    "np.random.seed(0)\n",
    "tf.set_random_seed(0)\n",
    "\n",
    "def xavier_init(fan_in , fan_out, constant=1): \n",
    "    \"\"\" Xavier initialization of network weights\"\"\"\n",
    "    # https://stackoverflow.com/questions/33640581/how-to-do-xavier-initialization-on-tensorflow\n",
    "#     fan_in = in_and_out[0]\n",
    "#     fan_out = in_and_out[1]\n",
    "    low = -constant*np.sqrt(6.0/(fan_in + fan_out)) \n",
    "    high = constant*np.sqrt(6.0/(fan_in + fan_out))\n",
    "    return tf.random_uniform((fan_in, fan_out), \n",
    "                             minval=low, maxval=high, \n",
    "                             dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Download 20 news group data completed\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "twenty_train = fetch_20newsgroups(subset='train')   \n",
    "data_ = twenty_train.data\n",
    "print(\"Download 20 news group data completed\")\n",
    "A = TextLoader(data_ , min_count = 25)\n",
    "batch_size = 100\n",
    "    # restricting memory usage, TensorFlow is greedy and will use all memory otherwise\n",
    "gpu_opts = tf.GPUOptions(per_process_gpu_memory_fraction=0.9)\n",
    "# initialize the Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = tf.InteractiveSession(config=tf.ConfigProto(gpu_options=gpu_opts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vae = NVDM(sess , len(A.vocab), 50, [500 , 500] ,  \n",
    "                         transfer_fct=tf.nn.tanh , output_activation=tf.nn.softmax,\n",
    "                         batch_size=100, initializer=xavier_init )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\liana\\anaconda3\\lib\\site-packages\\tensorflow\\python\\util\\tf_should_use.py:247: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n"
     ]
    }
   ],
   "source": [
    "vae.start_the_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [*] Loading checkpoints...\n",
      "Model dir is save_my_model\n",
      " ckpt name  NVDM-1000\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\liana\\Documents\\GitHub\\textsim\\vae\\Deep-Learning-Projects\\variational_text_inference\\save_my_model\\NVDM-1000\n",
      " [*] Load SUCCESS\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_model(vae)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = vae.SESS.run(vae.Weights_generator['out_mean'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 8466)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = embedding_matrix.transpose()\n",
    "embedding_matrix = find_norm(embedding_matrix) ####### Normalizing the matrix helps to find cosine similarity so fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.18270917 -0.20933783  0.15996052 ... -0.10757259 -0.07899398\n",
      "   0.17410365]\n",
      " [ 0.31164202  0.0486914   0.03740434 ...  0.02041274 -0.18702523\n",
      "   0.15251045]\n",
      " [-0.11786717  0.1953356  -0.10596441 ...  0.17624044 -0.1335527\n",
      "  -0.24091434]\n",
      " ...\n",
      " [-0.24149787 -0.05941224 -0.05474815 ...  0.03185274 -0.18754104\n",
      "  -0.12645514]\n",
      " [ 0.12785831 -0.22319151  0.1011028  ... -0.09852819 -0.09301905\n",
      "   0.12620029]\n",
      " [-0.09953024  0.15434173 -0.05730319 ... -0.1285125   0.11386734\n",
      "  -0.0882315 ]]\n",
      "[   1 2324 2943 6328 4488 1506  693 2446 4761]\n",
      "['thing', 'ariane', 'publisher', 'bissell', 'marlin', 'refer', '4', 'cds', '3000']\n"
     ]
    }
   ],
   "source": [
    "from vector_utils import find_similar\n",
    "print(embedding_matrix)\n",
    "\n",
    "sims, idx = find_similar(embedding_matrix, embedding_matrix[A.vocab[\"thing\"]])\n",
    "print(idx[:9])\n",
    "words = [A.vocab_inverse[x] for x in idx[:9]]\n",
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vector_utils import find_similar\n",
    "def word_match(norm_mat , word_ , vocab, vocab_inverse , topN = 10):\n",
    "    \n",
    "    idx = vocab[word_]\n",
    "    similarity_meas , indexes = find_similar(norm_mat , norm_mat[idx])\n",
    "    words = [vocab_inverse[i_x_] for i_x_ in indexes[:topN-1]]\n",
    "    return zip(words , similarity_meas[:topN-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "7898",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-f3c701da21d1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mword_match\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0membedding_matrix\u001b[0m \u001b[1;33m,\u001b[0m \u001b[1;34m'football'\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab_inverse\u001b[0m  \u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-27-04024299117e>\u001b[0m in \u001b[0;36mword_match\u001b[1;34m(norm_mat, word_, vocab, vocab_inverse, topN)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msimilarity_meas\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_mat\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnorm_mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvocab_inverse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi_x_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi_x_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtopN\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0msimilarity_meas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtopN\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-27-04024299117e>\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0midx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword_\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msimilarity_meas\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mindexes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm_mat\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mnorm_mat\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mwords\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mvocab_inverse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi_x_\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi_x_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mindexes\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtopN\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0msimilarity_meas\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtopN\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 7898"
     ]
    }
   ],
   "source": [
    "word_match(embedding_matrix , 'football' , A.vocab , A.vocab_inverse  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  1 10 ...  0  0  0]\n",
      " [ 0  0 14 ...  0  0  0]\n",
      " [ 1  0 24 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0 11 ...  0  0  0]\n",
      " [ 0  0  6 ...  0  0  0]\n",
      " [ 0  1  9 ...  0  0  0]]\n",
      "[[1 1 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [1 0 1 ... 0 0 0]\n",
      " ...\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 0 1 ... 0 0 0]\n",
      " [0 1 1 ... 0 0 0]]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot feed value of shape () for Tensor 'Placeholder:0', which has shape '(None, 7162)'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-52-f11c83d44e33>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     21\u001b[0m                                             vae.MASK:mask_xs}\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 23\u001b[1;33m             \u001b[0mh_batch\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSESS\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvae\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     24\u001b[0m             \u001b[0mH_20_grp_nws\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    955\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    956\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 957\u001b[1;33m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0m\u001b[0;32m    958\u001b[0m                          run_metadata_ptr)\n\u001b[0;32m    959\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1152\u001b[0m           if (not is_tensor_handle_feed and\n\u001b[0;32m   1153\u001b[0m               not subfeed_t.get_shape().is_compatible_with(np_val.shape)):\n\u001b[1;32m-> 1154\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m   1155\u001b[0m                 \u001b[1;34m'Cannot feed value of shape %r for Tensor %r, '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1156\u001b[0m                 \u001b[1;34m'which has shape %r'\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Cannot feed value of shape () for Tensor 'Placeholder:0', which has shape '(None, 7162)'"
     ]
    }
   ],
   "source": [
    "################# Pickup the hidden dimensions for all 20 news groups\n",
    "batch_size = 100\n",
    "H_20_grp_nws = []\n",
    "batch_data = A.get_batch(batch_size)\n",
    "batch_id = 0\n",
    "#for i in A.get_batch(100):\n",
    "#    for x in i:\n",
    "        #print(x)\n",
    "        \n",
    "for batch_ in batch_data:\n",
    "\n",
    "            batch_id += 1\n",
    "            collected_data = [chunks for chunks in batch_]\n",
    "            #print(collected_data)\n",
    "            #print(A._bag_of_words(collected_data))\n",
    "            batch_xs , mask_xs , mask_negative  = A._bag_of_words(collected_data)\n",
    "            \n",
    "            print(batch_xs)\n",
    "            print(mask_xs)\n",
    "            feed_dict = {vae.X: batch_xs , vae.dynamic_batch_size:batch_xs.shape[0],\n",
    "                                            vae.MASK:mask_xs}\n",
    "            \n",
    "            h_batch    = vae.SESS.run(fetches = vae.z, feed_dict= feed_dict)\n",
    "            H_20_grp_nws.extend(h_batch)\n",
    "\n",
    "H_20_grp_nws = np.array(H_20_grp_nws)\n",
    "from sklearn import manifold\n",
    "tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "%time H_tsne = tsne.fit_transform(H_20_grp_nws) ########### Converting to tsne\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "############ Picking only non - null values after pre-processing ( The non null indexes of data is in self.data_index)\n",
    "newsgroups_target = [twenty_train.target[i] for i in A.data_index]\n",
    "########### Converting targets to One-hot-K Vectors by tf.one_hot for visualization purposes\n",
    "news_target_one_hot = sess.run(tf.one_hot(newsgroups_target , depth=len(set(newsgroups_target))))\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6)) \n",
    "plt.scatter(H_tsne[:, 0], H_tsne[:, 1], c=np.argmax(news_target_one_hot, 1))\n",
    "plt.colorbar()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def find_similiar_docs(index, topN = 10):\n",
    "\n",
    "    a , b = find_similar(find_norm(H_20_grp_nws), find_norm(H_20_grp_nws)[index])\n",
    "    source = data_[index]\n",
    "    similar_results = [data_[i] for i in b[1:topN]]\n",
    "    \n",
    "    return source , zip(similar_results, a[1:topN])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'H_20_grp_nws' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-e828b59c1186>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mquery\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_similiar_docs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1797\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-21-687bca03b50f>\u001b[0m in \u001b[0;36mfind_similiar_docs\u001b[1;34m(index, topN)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mfind_similiar_docs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtopN\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0ma\u001b[0m \u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfind_similar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfind_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH_20_grp_nws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfind_norm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mH_20_grp_nws\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m     \u001b[0msource\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0msimilar_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mdata_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtopN\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'H_20_grp_nws' is not defined"
     ]
    }
   ],
   "source": [
    "query , res = find_similiar_docs(1797)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
